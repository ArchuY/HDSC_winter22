{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# HDSC Winter '22 Stage D Kaggle Project\n## Name: Archana Yadav\n## Hamoye ID: 147eb872a001f000","metadata":{}},{"cell_type":"markdown","source":"## 1. PREPROCESS DATA\n\n","metadata":{"id":"okbCcmr-AKeN"}},{"cell_type":"code","source":"import tensorflow as tf\nprint(tf.__version__)\nprint(tf.config.list_physical_devices('GPU'))\ntf.random.set_seed(142)","metadata":{"id":"tk25CTnbAKeP","outputId":"57c0b1e4-3275-4c30-f52e-a6088953c88a","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten, BatchNormalization\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D\nimport tensorflow_addons as tfa\nfrom tensorflow_addons.metrics import FBetaScore \n\nimport tqdm.notebook as tq\nimport os\nimport logging\nimport warnings\nwarnings.filterwarnings('ignore')\nlogging.getLogger(\"tensorflow\").setLevel(logging.ERROR)","metadata":{"id":"XH8tpRS4AKeZ","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"proj_fold = '../input/planets-dataset/planet'\ndata_path = os.path.join(proj_fold, \"planet\")\ntrain_dir_path = os.path.join(data_path, \"train-jpg\")\ntrain_csv_path = os.path.join(data_path, \"train_classes.csv\")","metadata":{"id":"2-13F4c6AKee","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(train_csv_path)\ndf.head(5)","metadata":{"id":"9eU0c0tEAKeq","outputId":"6c9ab53b-148a-4cd9-b183-57815d205642","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dummies = df['tags'].str.get_dummies(' ')\ndf = pd.concat([df, dummies], axis=1)\n\nlabels = dummies.columns.values\nunique_val= len(labels)\ndummies","metadata":{"id":"QR7iDLE6fjXS","outputId":"c9a08ae6-9221-4708-91ff-cfa590e6a5b7","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"There are {unique_val} unique labels including {labels}\")","metadata":{"id":"uikCay2VgSTD","outputId":"6242d15d-9e76-4dc4-9918-953e819d777a","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Countplot of label distribution\nlabel_count = dummies.sum(axis=0).sort_values()\nprint(label_count)","metadata":{"id":"DiUVsr-BAKe6","outputId":"3f42b74a-9e97-4c58-f0b4-195a2682bc95","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label_count.plot(kind='barh', figsize=(15, 10))\nfor i in range(label_count.shape[0]):\n    plt.text(label_count.iloc[i] + 4, i, label_count.iloc[i], va='center')","metadata":{"id":"ICV-f3HaJ0za","outputId":"67b3d39b-a2a8-4562-e8e3-743e58514094","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images_title = [df[df['tags'].str.contains(label)].iloc[i]['image_name'] + '.jpg' for i, label in enumerate(labels)]","metadata":{"id":"X1VWGiQqAKe-","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"_, axs = plt.subplots(6, 3, sharex='col', sharey='row', figsize=(10, 20))\naxs = axs.ravel()\n\nfor i, (image_name, label) in enumerate(zip(images_title, labels)):\n    img_path = os.path.join(train_dir_path, image_name)\n    img = plt.imread(img_path)\n    axs[i].imshow(img)\n    axs[i].set_title(f'{image_name} - {label}')","metadata":{"id":"LRspWxPoAKfB","outputId":"8c329f3f-4b55-44d4-fcf5-225578250abd","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install iterative-stratification","metadata":{"id":"dKX0NI_cooyr","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from iterstrat.ml_stratifiers import MultilabelStratifiedKFold","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y = df[labels].values\nX = df['image_name'].values\n\ndf['fold'] = np.nan\n\nmskf = MultilabelStratifiedKFold(n_splits=5)\nfor i, (_, test_index) in enumerate(mskf.split(X, y)):\n    df.iloc[test_index, -1] = i\n   \ndf['fold'] = df['fold'].astype('int')\ndf['is_valid'] = False\ndf['is_valid'][df['fold'] == 0] = True","metadata":{"id":"k2EkIwUlqDg_","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Number of observations of each tags in each fold. \ndf.groupby('fold')[labels].sum()","metadata":{"id":"0FZd2KXErvFK","outputId":"97790f00-7e67-41cf-a140-f5edfcddb56d","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_size = df.shape[0] - df['is_valid'].sum()\nval_size = df['is_valid'].sum()","metadata":{"id":"1NlQC_bKtcHi","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Export raw data to TFRecords","metadata":{"id":"Y69Fpw-9cNHP"}},{"cell_type":"code","source":"# Converting the values into features\n\ndef _image_feature(value):\n    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[tf.io.encode_jpeg(value).numpy()]))\n\ndef _int64_feature(value):\n    if type(value) != list:\n        value = [value]\n    return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n\ndef _bytes_feature(value):\n    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n    if isinstance(value, type(tf.constant(0))): # if value ist tensor\n        value = value.numpy()\n    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n\ndef serialize_array(array):\n    array = tf.io.serialize_tensor(array)\n    return array\n\n\ndef image_feature(path, label):\n    image = plt.imread(path)\n\n    # image = tf.io.decode_jpeg(image, channels=3)\n    feature = {'height': _int64_feature(image.shape[0]),\n               'width': _int64_feature(image.shape[1]),\n               'channel': _int64_feature(image.shape[2]),\n               'image': _bytes_feature(serialize_array(image)),\n               'label': _int64_feature(label),}\n    return tf.train.Example(features=tf.train.Features(feature=feature))\n\n\ndef create_record(df, record_name):\n    all_image_paths = df['image_name'].apply(lambda x: os.path.join(TRAIN_JPG_DIR, x+'.jpg')).values\n    all_labels = df[labels].values\n\n    record_path = f\"{record_name}.tfrecords\"\n    writer = tf.io.TFRecordWriter(record_path) \n\n    for i in tq.tqdm(range(df.shape[0])):\n        path = all_image_paths[i]\n        label = all_labels[i].tolist()\n        example = image_feature(path, label)\n        writer.write(example.SerializeToString())\n    \n    writer.close()","metadata":{"id":"8JM4MLD2cK4s","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for i in range(5): \n#     create_record(df[df['fold'] == i], f'fold_{i}')","metadata":{"id":"IlNSxknSbCvm","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#arch\nrecords = tf.io.gfile.glob(str('../input/tfrecord-files/*.tfrecords'))\nrecords","metadata":{"id":"Y7VW2Orln7Yd","outputId":"238868b2-f5e3-4c82-e345-ce33ea20a929","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMG_WIDTH, IMG_HEIGHT = 192, 192\nCHANNELS = 3\n\ndef read_tfrecord(example):\n    tfrecord_format = {\n        \"height\": tf.io.FixedLenFeature([], tf.int64),\n        \"width\": tf.io.FixedLenFeature([], tf.int64),\n        \"channel\": tf.io.FixedLenFeature([], tf.int64),\n        \"image\": tf.io.FixedLenFeature([], tf.string),\n        \"label\": tf.io.FixedLenFeature([17], tf.int64, default_value=np.zeros((17,)).astype('int').tolist())\n    }\n    example = tf.io.parse_single_example(example, tfrecord_format)\n\n    # Extract information\n    height = example['height']\n    width = example['width']\n    channel = example['channel']\n    image = example['image']\n    label = example['label']\n\n    # Convert raw image back to array\n    image = tf.io.parse_tensor(image, out_type=tf.uint8)\n    image = tf.reshape(image, shape=[height, width, channel])\n    if channel == 4:\n        image = image[:,:,:3]\n\n    image = tf.image.resize(image, [IMG_WIDTH, IMG_HEIGHT])\n\n    return (image, label)","metadata":{"id":"4NBEQ1GjpKzq","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 64\nSHUFFLE_BUFFER_SIZE = 1024\nAUTOTUNE = tf.data.experimental.AUTOTUNE","metadata":{"id":"jTXjCh9IzMAL","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def augmentation(image, label):\n    image = tf.image.random_brightness(image, .1)\n    image = tf.image.random_contrast(image, lower=0.0, upper=1.0)\n    image = tf.image.random_flip_left_right(image)\n    image = tf.image.random_flip_up_down(image)\n    return image, label\n\ndef load_dataset(filenames, shuffle=False, augment=False):\n    \"\"\"Load a list of pahts of TFRecords \n       and split them into train and validation set.\"\"\"\n\n    dataset = tf.data.TFRecordDataset(filenames)\n    dataset = dataset.map(read_tfrecord, num_parallel_calls=AUTOTUNE)\n\n    # dataset = dataset.cache()\n\n    if shuffle == True:\n        dataset = dataset.shuffle(buffer_size = SHUFFLE_BUFFER_SIZE).repeat()\n\n    if augment == True:\n        dataset.map(augmentation, num_parallel_calls=AUTOTUNE)\n    \n    dataset = dataset.batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n    \n    return dataset","metadata":{"id":"yHVuWP6J9nIh","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"records","metadata":{"id":"BWaofScpOMHO","outputId":"33a457a6-040d-4c76-a6d5-de740509f1cb","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ds = load_dataset(records[:4], shuffle=True, augment=True)\nval_ds = load_dataset(records[4], shuffle=False, augment=False)","metadata":{"id":"Uy6TbZEL2Dje","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ds","metadata":{"id":"iUhInfwH2gm8","outputId":"f750794a-4174-4af4-840e-64f30230f5d4","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_ds","metadata":{"id":"h6RIZyMtOZix","outputId":"2234da9e-e7f6-4492-bf89-0ad2e90c355b","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in train_ds.take(1):\n    plt.imshow(i[0][1].numpy() / 255.)\n    plt.show()","metadata":{"id":"j-Izl3CLxLxM","outputId":"0a56f389-4101-453f-d762-55deeebe4d8b","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample = df[df['fold'] == 0]\nsample.head()","metadata":{"id":"T03MaplCMsuw","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample[labels].sum() / df[labels].sum()","metadata":{"id":"w12CBkK0NxFI","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. MODELLING","metadata":{"id":"0tjMQrmzAKhr"}},{"cell_type":"code","source":"def build_model(trainable = False, fine_tune_at = 0):\n    \n    mobile_net = tf.keras.applications.MobileNetV3Large(input_shape=(IMG_WIDTH, IMG_HEIGHT, CHANNELS), include_top=False)\n    if trainable == True:\n        mobile_net.trainable=True\n    \n        for layer in mobile_net.layers[:fine_tune_at]:\n            layer.trainable = False\n    else: \n        mobile_net.trainable = False\n        \n    \n    input = tf.keras.Input(shape=(IMG_WIDTH, IMG_HEIGHT, CHANNELS), name='input')\n    x = tf.keras.applications.mobilenet_v3.preprocess_input(input)\n    x = mobile_net(x)\n    x = tf.keras.layers.Dense(1024, activation = 'relu')(x)\n    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n    output = tf.keras.layers.Dense(unique_val, activation = 'sigmoid')(x)\n    model = tf.keras.Model(input, output)\n    return model","metadata":{"id":"p1qNc6RMAKhu","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = build_model()\nmodel.summary()","metadata":{"id":"57jR3XSfAKh0","outputId":"0f8fb383-2732-46af-c903-2ee4870214f8","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for batch in train_ds: \n    print(model.predict(batch[0]))\n    break","metadata":{"id":"EB8c2u_BAKh7","outputId":"66b50849-2d50-42c3-9a44-c50efc8c5f3e","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ES_PATIENCE = 5\nRLROP_PATIENCE = 3\nDECAY_DROP = 0.5","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"early_stop = EarlyStopping(monitor='val_loss', mode='min', patience=ES_PATIENCE, restore_best_weights=True, verbose=1)\nlr_decay = ReduceLROnPlateau(monitor='val_loss', mode='min', patience=RLROP_PATIENCE, factor=DECAY_DROP, min_lr=1e-6, verbose=1)\n\ncp_callback = [early_stop, lr_decay]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"LR = 1e-5\nEPOCHS = 40\nnum_steps_train = tf.math.ceil(float(train_size)/BATCH_SIZE)              \nnum_steps_val = tf.math.ceil(float(val_size)/BATCH_SIZE)\n\nfbeta = FBetaScore(num_classes=unique_val,\n                   average='weighted',\n                   beta=2.0,\n                   threshold=0.2,\n                   name='fbeta')","metadata":{"id":"A0arh9ogAKiI","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compile model with optimizer\nmodel.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = LR),\n               loss = 'binary_crossentropy',\n               metrics = [fbeta, tf.keras.metrics.AUC()])","metadata":{"id":"RRigRCkL0wU9","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train model\nhistory = model.fit(train_ds,\n                  steps_per_epoch = num_steps_train,\n                  epochs = EPOCHS,\n                  validation_data = val_ds,\n                  validation_steps = num_steps_val,\n                  callbacks=[cp_callback, lr_decay], verbose = 2)","metadata":{"id":"hM4WLxQQAKiL","outputId":"2b4b66c4-fd0c-42e3-fdac-496e8e979995","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" def plot_stats(training_stats, val_stats, x_label='Training Steps', stats='loss'):\n    stats, x_label = stats.title(), x_label.title()\n    legend_loc = 'upper right' if stats=='loss' else 'lower right'\n    training_steps = len(training_stats)\n    test_steps = len(val_stats)\n\n    plt.figure()\n    plt.ylabel(stats)\n    plt.xlabel(x_label)\n    plt.plot(training_stats, label='Training ' + stats)\n    plt.plot(np.linspace(0, training_steps, test_steps), val_stats, label='Validation ' + stats)\n    plt.ylim([0,max(plt.ylim())])\n    plt.legend(loc=legend_loc)\n    plt.show()","metadata":{"id":"Wru2EJEVesdB","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (15, 10))\n\nplot_stats(history.history['loss'], history.history['val_loss'], x_label='Epochs', stats='loss')\nplot_stats(history.history['fbeta'], history.history['val_fbeta'], x_label='Epochs', stats='fbeta');","metadata":{"id":"bsHSRXFiAKiW","outputId":"4039f531-063c-4c06-b4bf-903a02885a3c","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SAVE_PATH = '/kaggle/working/model/1_full_decay.h5'\nmodel.save(SAVE_PATH)","metadata":{"id":"aN_L4Vh3e4g-","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = tf.keras.models.load_model(SAVE_PATH)","metadata":{"id":"ehkDtO4oAKif","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def read_tfrecord_label_only(example):\n    tfrecord_format = {\n        \"height\": tf.io.FixedLenFeature([], tf.int64),\n        \"width\": tf.io.FixedLenFeature([], tf.int64),\n        \"channel\": tf.io.FixedLenFeature([], tf.int64),\n        \"image\": tf.io.FixedLenFeature([], tf.string),\n        \"label\": tf.io.FixedLenFeature([17], tf.int64, default_value=np.zeros((17,)).astype('int').tolist())\n    }\n    example = tf.io.parse_single_example(example, tfrecord_format)\n\n    # Extract information\n    height = example['height']\n    width = example['width']\n    channel = example['channel']\n    image = example['image']\n    label = example['label']\n\n    return label","metadata":{"id":"Wd4FSue_SnPP","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_label_ds = tf.data.TFRecordDataset(records[:4])\ntrain_label_ds = train_label_ds.map(read_tfrecord_label_only, num_parallel_calls=AUTOTUNE)","metadata":{"id":"vQD_k2OA9V2a","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"true = list(train_label_ds.as_numpy_iterator())\ntrue = np.array(true)\ntrue.shape","metadata":{"id":"nzyLIZiaUPdF","outputId":"5e47dc1e-90be-4c4e-b175-b0704abed959","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_image_ds = load_dataset(records[:4], shuffle=False, augment=False)","metadata":{"id":"U2HRAycM9k7w","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = model.predict(train_image_ds)\nfinal_predictions = (predictions > 0.2).astype('int')\nfinal_predictions.shape","metadata":{"id":"z7QCYr-rky6o","outputId":"5e4d5fed-a75c-48e0-cfbd-108d61d11782","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import fbeta_score\nfbeta_score(true, final_predictions, average='weighted', beta=2)","metadata":{"id":"3zuGe8kBEjgr","outputId":"f6929f25-1f60-4f7c-c09b-688599306c71","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\nprint(classification_report(true, final_predictions))","metadata":{"id":"goUYQI0uzzUt","outputId":"79d8af09-d3ba-4210-93f4-a5d6a2d0e37e","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for data in train_image_ds.take(1):\n    sample_images = data[0].numpy().astype('int')\n    sample_labels = data[1].numpy().astype('bool')\n\nsample_images = sample_images[:40]\nsample_labels = sample_labels[:40]\nsample_predictions = final_predictions[:40]","metadata":{"id":"UN3OYQS7hJ_4","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(10, 4, figsize=(20, 30))\naxes = axes.ravel()\n\nfor i, (image, label) in enumerate(zip(sample_images, sample_labels)):\n    axes[i].imshow(image)\n    predict_label = labels[sample_predictions[i] == 1]\n    predict_label = ', '.join(predict_label)\n    correct = ', '.join(labels[label])\n    axes[i].set_title(f\"PREDICT: {predict_label} \\nCORRECT: {correct}\")\n\nplt.subplots_adjust(wspace=1, hspace=1)\nplt.show()","metadata":{"id":"dDGN6USAh5Kt","outputId":"a87f031d-c84a-4377-cb45-3f5450c26e9a","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. TUNING THRESHOLD","metadata":{"id":"skG8GPTEAKjU"}},{"cell_type":"code","source":"def perf_grid(y_hat_val, y_val, label_names, n_thresh=100):\n    \n    # Find label frequencies in the validation set\n    label_freq = y_val.sum(axis=0)\n\n    # Define thresholds\n    thresholds = np.linspace(0, 1, n_thresh+1).astype(np.float32)\n    \n    # Compute all metrics for all labels\n    ids, labels, freqs, tps, fps, fns, precisions, recalls, f1s, f2s = [], [], [], [], [], [], [], [], [], []\n    \n    for i in tq.tqdm(range(len(label_names))):\n        for thresh in thresholds:   \n            ids.append(i)\n            labels.append(label_names[i])\n            freqs.append(round(label_freq[i]/len(y_val),2))\n\n            y = y_val[:, i]\n            y_pred = y_hat_val[:, i] > thresh\n\n            tp = np.count_nonzero(y_pred  * y)\n            fp = np.count_nonzero(y_pred * (1-y))\n            fn = np.count_nonzero((1-y_pred) * y)\n            precision = tp / (tp + fp + 1e-16)\n            recall = tp / (tp + fn + 1e-16)\n            f1 = 2*tp / (2*tp + fn + fp + 1e-16)\n            f2 = fbeta_score(y, y_pred, average='weighted', beta=2)\n            \n            tps.append(tp)\n            fps.append(fp)\n            fns.append(fn)\n            precisions.append(precision)\n            recalls.append(recall)\n            f1s.append(f1)\n            f2s.append(f2)\n            \n    # Create the performance dataframe\n    grid = pd.DataFrame({'id':ids,\n                         'label':labels,\n                         'freq':freqs,\n                         'threshold':list(thresholds)*len(label_names),\n                         'tp':tps,\n                         'fp':fps,\n                         'fn':fns,\n                         'precision':precisions,\n                         'recall':recalls,\n                         'f1':f1s,\n                         'f2': f2s})\n    \n    return grid","metadata":{"id":"Fq8iiFrhAKjV","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions.shape","metadata":{"id":"56SMK-L8C10y","outputId":"b8adab74-ce61-4e8a-8e0f-df00298d5722","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"true.shape","metadata":{"id":"A1CLqZ4UC3bY","outputId":"68855ce1-99b2-443c-c5c0-9f7998f62d9a","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Performance table\ngrid = perf_grid(predictions, true, labels)","metadata":{"id":"xqLAZm2VAKjX","outputId":"384d173b-f5ae-4d49-e4bf-ab23418b6a48","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grid[grid['label'].str.contains('primary')].head(20)","metadata":{"id":"yES5L593AKjb","outputId":"a6c5e896-b043-407d-bb72-993ddeec5ba1","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Choose the best threshold of \ngrid_max = grid.loc[grid.groupby(['id', 'label'])[['f2']].idxmax()['f2'].values]\ngrid_max","metadata":{"id":"e4rpZNOkFQk6","outputId":"822a82c0-e8ba-452e-cea6-4d1aa9d9b7b1","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4. PREDICT ON TEST ","metadata":{"id":"FemZvSVMcjsj"}},{"cell_type":"code","source":"test_paths = tf.io.gfile.glob(str(data_path + '/test-jpg/*.jpg')) \nadditional_paths = tf.io.gfile.glob(str('../input/planets-dataset/test-jpg-additional' + '/test-jpg-additional/*.jpg')) ","metadata":{"id":"Kt37z1tc6JuF","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(test_paths)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(additional_paths)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_test_record(data_folder, record_name):\n    paths = tf.io.gfile.glob(str(data_folder + f'/{record_name}/*.jpg')) \n\n    record_path = f\"./{record_name}.tfrecords\"\n    writer = tf.io.TFRecordWriter(record_path) \n\n    for i in tq.tqdm(range(len(paths))):\n        path = paths[i]\n        image = plt.imread(path)\n        feature = {'height': _int64_feature(image.shape[0]),\n                   'width': _int64_feature(image.shape[1]),\n                   'channel': _int64_feature(image.shape[2]),\n                   'image': _bytes_feature(serialize_array(image))}\n        example = tf.train.Example(features=tf.train.Features(feature=feature))\n        writer.write(example.SerializeToString())\n    writer.close()","metadata":{"id":"nlDF5lDYmja3","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"create_test_record(data_path,'test-jpg')\ncreate_test_record(\"../input/planets-dataset/test-jpg-additional\",'test-jpg-additional')","metadata":{"id":"BHF1InSHoHAO","outputId":"64b792e8-47fb-4368-e527-22b6357ad15d","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def read_test_record(example): \n    tfrecord_format = {\n            \"height\": tf.io.FixedLenFeature([], tf.int64),\n            \"width\": tf.io.FixedLenFeature([], tf.int64),\n            \"channel\": tf.io.FixedLenFeature([], tf.int64),\n            \"image\": tf.io.FixedLenFeature([], tf.string)\n            }\n\n    example = tf.io.parse_single_example(example, tfrecord_format)\n\n    # Extract information\n    height = example['height']\n    width = example['width']\n    channel = example['channel']\n    image = example['image']\n\n    # Convert raw image back to array\n    image = tf.io.parse_tensor(image, out_type=tf.uint8)\n    image = tf.reshape(image, shape=[height, width, channel])\n    if channel == 4:\n        image = image[:,:,:3]\n\n    image = tf.image.resize(image, [IMG_WIDTH, IMG_HEIGHT])\n    return image","metadata":{"id":"BKmlQ6RMlcIp","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_test_dataset(filenames, shuffle=False, augment=False):\n    dataset = tf.data.TFRecordDataset(filenames)\n    dataset = dataset.map(read_test_record, num_parallel_calls=AUTOTUNE)\n    dataset = dataset.batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n    \n    return dataset","metadata":{"id":"G2MHYtxuqM2X","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"records = tf.io.gfile.glob('./*.tfrecords')\nrecords","metadata":{"id":"WkK4l7TU7EKX","outputId":"5e38230d-919c-4fc7-e186-e33621ff0a09","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_ds = load_test_dataset(records[-1])\nadditional_ds = load_test_dataset(records[-2])","metadata":{"id":"8aY-hRBCjX3B","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"records[-2]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_predictions = model.predict(test_ds)\nadditional_predictions = model.predict(additional_ds)","metadata":{"id":"b9MCvYt9hWdT","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(test_predictions)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(additional_predictions)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"threshold = { 'agriculture':0.164,\n          'artisinal_mine':0.114,\n          'bare_ground':0.138,\n          'blooming':0.168,\n          'blow_down':0.2,\n          'clear':0.13,\n          'cloudy':0.076,   \n          'conventional_mine':0.1,\n          'cultivation':0.204,\n          'habitation':0.17,\n          'haze':0.204,\n          'partly_cloudy':0.112,\n          'primary':0.204,\n          'road':0.156,\n          'selective_logging':0.154,\n          'slash_burn':0.38,\n          'water':0.182\n            }\n            \nthresholds = np.fromiter(threshold.values(), dtype=float)","metadata":{"id":"hTeRtUpnKKSV","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_tag(prediction):\n    return ' '.join(labels[(prediction >= thresholds)])","metadata":{"id":"HjpzONbzx2xY","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"get_tag","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_test_predictions = list(map(get_tag, test_predictions))\nfinal_additional_predictions = list(map(get_tag, additional_predictions))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(final_additional_predictions)","metadata":{"id":"MP8caXV8HY4F","outputId":"b6f10e00-a28c-4170-d04a-9bfa6c7f5eed","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(final_test_predictions)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_filenames = list(map(lambda x: x.split('/')[-1][:-4], test_paths))\nadditional_filenames = list(map(lambda x: x.split('/')[-1][:-4], additional_paths))","metadata":{"id":"Q_-3QpEczB-L","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(additional_filenames)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(test_filenames)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.DataFrame({'image_name': test_filenames, 'tags': final_test_predictions})\nsubmission['count'] = submission['image_name'].str.strip('test_').astype('int')\nsubmission = submission.sort_values('count', ascending=True).reset_index(drop=True)\nsubmission.drop(columns=['count'], inplace=True)\nsubmission","metadata":{"id":"7s2G-yYt0Duj","outputId":"d002762d-268d-46eb-f3b0-2db29abe9675","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_2 = pd.DataFrame({'image_name': additional_filenames, 'tags': final_additional_predictions})\nsubmission_2['count'] = submission_2['image_name'].str.strip('file_').astype('int')\nsubmission_2 = submission_2.sort_values('count', ascending=True).reset_index(drop=True)\nsubmission_2.drop(columns=['count'], inplace=True)\nsubmission_2","metadata":{"id":"WCUaFLp4zzDP","outputId":"812dae97-166f-4fef-d6c6-1a39c1538ffb","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_submission = pd.concat([submission, submission_2], axis=0)\nfinal_submission","metadata":{"id":"-BNYfR2e-Ngf","outputId":"dbc0123e-37c9-4f74-e9f8-261a969b6c26","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_submission.to_csv(\"staged_submission.csv\", index=False)","metadata":{"id":"y8lfyJJO0t2_","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}